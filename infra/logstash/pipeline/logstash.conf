input {
  jdbc {
    jdbc_driver_library => "/usr/share/logstash/logstash-core/lib/jars/postgresql-42.2.13.jar"
    jdbc_driver_class => "org.postgresql.Driver"
    jdbc_connection_string => "jdbc:postgresql://postgres:5432/DEV?schema=public?"
    jdbc_user => "postgres"
    jdbc_password => "postgres"
    # Pagination for large data sets
    jdbc_paging_enabled => true
    jdbc_page_size => 50000
    schedule => "*/3 * * * *" # 매 분마다 실행
    # SQL query to select data from Post table
    statement => "select 
                    u.id as ownerId,
                    u.email as ownerEmail,
                    p.*
                  from public.posts p
                  inner join public.users u
                  on u.id = p.user_id"
                  
    use_column_value => true
    tracking_column => "updated_at"
    tracking_column_type => "timestamp"
     # Enable deletions (assumes a deleted_at column is used to mark deletions)
    record_last_run => true
    last_run_metadata_path => "/usr/share/logstash/.logstash_jdbc_last_run"
  }
}

output {
  elasticsearch{
    hosts => ["http://elasticsearch:9200"]  # Elasticsearch server address
    index => "post_index"  # Elasticsearch index name
    
    # Document ID configuration (use the PostgreSQL primary key)
    document_id => "%{id}"
    
    # Optional action (use "update" to update existing documents)
    action => "%{[@metadata][action]}"
  }
  stdout {
    codec => rubydebug
  }
}

filter {
  if [removed_at] {
    mutate {
      add_field => { "[@metadata][action]" => "delete" }
    }
  } else {
    mutate {
      add_field => { "[@metadata][action]" => "index" }
    }
  }
}